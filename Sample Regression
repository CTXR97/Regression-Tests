from sklearn.linear_model import LinearRegression
x1 = np.array(df_data2['real costs - by persons employed/%']).reshape(-1,1) x2 = np.array(df_data2['real costs - by hours worked/%']).reshape(-1,1)
y = np.array(df_data2['GDP per hour worked/USD']).reshape(-1,1)
# 3.3.1 real costs - by persons employed/% and labour productivity/%构造一元线性回归 #构造回对象
model_1 = LinearRegression()
model_1.fit(x1, y)
#获取预测值
predict_y = model_1.predict(x1)
#构造返回对象
predictions = {}
predictions['intercept'] = model_1.intercept_ #截距 predictions['coefficient'] = model_1.coef_ #斜率(回归系数) predictions['predict_value'] = predict_y
#绘图
#绘出已知数据散点图 plt.scatter(x1, y, color = 'blue')
#绘制预测直线
plt.plot(x1, predict_y, color = 'red', linewidth = 3)
plt.title('predict GDP per hour worked by persons employed')
plt.xlabel('real costs - by persons employed/%')
plt.ylabel('GDP per hour worked/USD')
plt.show()

print(predictions)

#### 统计量参数
def get_model_stats(x, y, model):
message0 = f'一元线性回归方程为: \ty = {model.intercept_[0]:.3f} + {model.coef_[0][0]:.3f}*x1' 

from scipy import stats

n = len(x)
y_prd = model.predict(x)
    Regression = sum((y_prd - np.mean(y))**2) # 回归
    Residual = sum((y - y_prd)**2) # 残差
    R_square = Regression / (Regression + Residual) # 相关性系数R^2
    F = (Regression / 1) / (Residual / ( n - 2 )) # F 分布
pf = = stats.f.sf(F, 1, n- 2)
message1 =(f'相关系数(R^2): {R_square[0]:.3f};\n' +
f'回归分析(SSR): {Regression[0]:.3f};\t 残差(SSE):{Residual[0]:.3f};\n' + f' F : {F[0]:.3f};\t pf : {pf[0]}')

## T分布
L_xx = n
sigma = np.sqrt(Residual / (n- 2))
t = model.coef_ * np.sqrt(L_xx) / sigma
pt = stats.t.sf(t, n- 2)
message2 = f' t : {t[0][0]:.3f}; pt : {pt[0][0]}' return print(message0 +'\n' +message1 + '\n'+message2)

get_model_stats(x1, y, model_1)
